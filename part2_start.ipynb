{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3950 Assignment 1: Part 2\n",
    "\n",
    "For this assignment we want to use some sort of tree based model to classify the data below. We have a very small training set, so overfitting is a very real concern. \n",
    "\n",
    "Some specifics for this assignment:\n",
    "<ul>\n",
    "<li>Please use the show_eda to control if EDA stuff is shown. I don't really need to see all the EDA stuff (nor do you after you've done it), so we can make it configurable with a variable to speed up time. Please set this FALSE when you submit, so I can run all and see the outcome without histograms etc...\n",
    "<li>Please ensure that whatever model you end up with is in a variable named best at the end.\n",
    "<li>Please use some pipeline in prepping the data. The test data is in an identical format to the training data, so whatever pipeline you've created for your training will work for the testing. \n",
    "<li>The accuracy scoring will be an average of accuracy and roc_auc. \n",
    "</ul>\n",
    "\n",
    "### Grading Metrics\n",
    "<ul>\n",
    "<li><b>Pipeline Used - 10pts</b> The data loading needs to be in a pipeline. See the test part for illustration. When testing I'll call your pipe with the new data (format is identical to training), so any prep stuff should be in the pipeline. \n",
    "<li><b>Tree Based Model Used - 5pts</b> The model used for classification needs to be some variety of tree, beyond that it is up to you. \n",
    "<li><b>Accuracy - 5pts</b> The final accuracy acheived. This will be a rough ranking, I'm assuming most people will get a similar level of accuracy, marks will only be deducted if yours is far wosrse, as that's an indication that you probably didn't take any/many steps to improve things. \n",
    "<li><b>Clarity and Formatting - 5pts</b> Is it organized and can I read it?\n",
    "    <ul>\n",
    "    <li> <b>Note:</b> for this assignment, and in general, please get rid of my comments and replace them with your own. I'm going to read this, so all of these instructions aren't really required. Think of this as a template, get rid of the stuff that isn't needed, and leave only the things you need to explain your code. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "For submission, please drop the URL for your repository in the dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please change to your name.\n",
    "name = \"Stanley Song\"\n",
    "\n",
    "#Please use this to control EDA. \n",
    "show_eda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "171       1  0.668  0.570  0.079  0.841  0.871  0.268  0.304  0.455  0.416   \n",
       "175       0  0.727  0.462  0.184  0.176  0.915  0.991  0.575  0.324  0.762   \n",
       "154       0  0.410  0.138  0.492  0.752  0.189  0.665  0.567  0.807  0.432   \n",
       "94        1  0.091  0.446  0.506  0.891  0.228  0.183  0.109  0.895  0.030   \n",
       "172       1  0.172  0.362  0.280  0.002  0.596  0.972  0.060  0.083  0.340   \n",
       "\n",
       "     ...  var_191  var_192  var_193  var_194  var_195  var_196  var_197  \\\n",
       "171  ...    0.776    0.275    0.747    0.859    0.630    0.935    0.352   \n",
       "175  ...    0.473    0.802    0.308    0.747    0.248    0.230    0.014   \n",
       "154  ...    0.899    0.063    0.411    0.287    0.586    0.840    0.812   \n",
       "94   ...    0.769    0.104    0.336    0.365    0.794    0.900    0.587   \n",
       "172  ...    0.142    0.807    0.758    0.508    0.137    0.553    0.581   \n",
       "\n",
       "     var_198  var_199  var_200  \n",
       "171    0.540    0.344    0.769  \n",
       "175    0.907    0.182    0.435  \n",
       "154    0.135    0.137    0.157  \n",
       "94     0.945    0.301    0.877  \n",
       "172    0.106    0.388    0.907  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>0</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18864</th>\n",
       "      <td>0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13335</th>\n",
       "      <td>1</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "8436        0  0.876  0.569  0.708  0.576  0.305  0.551  0.198  0.042  0.348   \n",
       "11836       0  0.001  0.245  0.528  0.572  0.945  0.746  0.276  0.828  0.929   \n",
       "3206        1  0.766  0.223  0.770  0.314  0.310  0.879  0.193  0.123  0.901   \n",
       "18864       0  0.815  0.712  0.402  0.123  0.771  0.833  0.319  0.778  0.841   \n",
       "13335       1  0.640  0.839  0.712  0.622  0.493  0.511  0.252  0.587  0.091   \n",
       "\n",
       "       ...  var_191  var_192  var_193  var_194  var_195  var_196  var_197  \\\n",
       "8436   ...    0.864    0.984    0.205    0.236    0.751    0.318    0.467   \n",
       "11836  ...    0.067    0.268    0.668    0.895    0.621    0.165    0.555   \n",
       "3206   ...    0.404    0.149    0.352    0.870    0.623    0.378    0.256   \n",
       "18864  ...    0.999    0.741    0.446    0.969    0.174    0.178    0.493   \n",
       "13335  ...    0.293    0.106    0.108    0.211    0.263    0.965    0.476   \n",
       "\n",
       "       var_198  var_199  var_200  \n",
       "8436     0.906    0.615    0.350  \n",
       "11836    0.755    0.727    0.034  \n",
       "3206     0.632    0.166    0.515  \n",
       "18864    0.005    0.785    0.438  \n",
       "13335    0.526    0.311    0.092  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"testing.csv\")\n",
    "df2 = df2.drop(columns={\"id\"})\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting\n",
    "\n",
    "For this assignment, you have a small training set, so combatting overfitting is key in being accurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 201)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19750, 201)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Columns: 201 entries, target to var_200\n",
      "dtypes: float64(200), int64(1)\n",
      "memory usage: 392.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started with a basic DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479493670886076\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = np.array(df['target']).reshape(-1, 1)\n",
    "x_train = np.array(df.drop(columns={'target'}))\n",
    "\n",
    "y_test = np.array(df2['target']).reshape(-1, 1)\n",
    "x_test = np.array(df2.drop(columns={'target'}))\n",
    "\n",
    "pipeline = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=5, min_samples_split=3))\n",
    "]\n",
    "\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "score = pipe.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasn't too accurate so I switched to a RandomForestClassifier and found better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504303797468355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = np.array(df['target']).reshape(-1, 1)\n",
    "x_train = np.array(df.drop(columns={'target'}))\n",
    "\n",
    "y_test = np.array(df2['target']).reshape(-1, 1)\n",
    "x_test = np.array(df2.drop(columns={'target'}))\n",
    "\n",
    "pipeline = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy',\n",
    "                                        max_depth=10, \n",
    "                                        min_samples_split=5,\n",
    "                                        n_estimators=150))\n",
    "]\n",
    "\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "score = pipe.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built a gridsearch to help find better hyperparameters, although I found it too sometimes inaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_split=5,\n",
       "                       n_estimators=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_split=5,\n",
       "                       n_estimators=80)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=5,\n",
       "                       n_estimators=80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_para = {'min_samples_split':[2,3,4,5],\n",
    "            'max_depth':[8,10,15,20,50],\n",
    "            'n_estimators':[20,80,200,500],\n",
    "            'criterion':[\"gini\",\"entropy\"]\n",
    "            }\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=tree_para, cv=5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what I learned by testing out many different types and amounts I ended up with with these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6845569620253165\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(df['target']).reshape(-1, 1)\n",
    "x_train = np.array(df.drop(columns={'target'}))\n",
    "\n",
    "y_test = np.array(df2['target']).reshape(-1, 1)\n",
    "x_test = np.array(df2.drop(columns={'target'}))\n",
    "\n",
    "pipeline = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                        max_depth=20,\n",
    "                                        min_samples_leaf=4, \n",
    "                                        min_samples_split=6,\n",
    "                                        n_estimators=500))\n",
    "]\n",
    "\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "score = pipe.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a system to combine the pipeline and gridsearch method in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6671392405063291\n",
      "Best parameters: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(max_depth=8, min_samples_split=3,\n",
      "                                        n_estimators=400))])\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(df['target']).reshape(-1, 1)\n",
    "x_train = np.array(df.drop(columns=['target']))\n",
    "\n",
    "y_test = np.array(df2['target']).reshape(-1, 1)\n",
    "x_test = np.array(df2.drop(columns=['target']))\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Parameters \n",
    "tree_para = {\n",
    "    'classifier__min_samples_split': [2, 3, 4, 5],\n",
    "    'classifier__max_depth': [8, 10, 15, 25, 40],\n",
    "    'classifier__n_estimators': [200, 300, 400, 500, 600],\n",
    "    'classifier__criterion': [\"gini\", \"entropy\"]   \n",
    "}\n",
    "\n",
    "# Use GridSearch method to find best parameters\n",
    "pipe = GridSearchCV(estimator=pipeline, param_grid=tree_para, cv=5, n_jobs=-1)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "pipe.fit(x_train, y_train)  \n",
    "\n",
    "best_estimator = pipe.best_estimator_\n",
    "\n",
    "score = best_estimator.score(x_test, y_test)  \n",
    "print(\"Best score:\", score)\n",
    "print(\"Best parameters:\", best_estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing\n",
    "\n",
    "At the conclusion, please name your best model \"best\". If you look down below in the testing stuff, it should be usable to score as \"best\". \n",
    "\n",
    "You should be able to call it like this and it should work (with whatever data names you have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6753924050632911\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=20,\n",
      "                                        min_samples_leaf=4, min_samples_split=3,\n",
      "                                        n_estimators=500))])\n"
     ]
    }
   ],
   "source": [
    "# My best Model\n",
    "\n",
    "Y_train = np.array(df['target']).reshape(-1, 1)\n",
    "X_train = np.array(df.drop(columns={'target'}))\n",
    "\n",
    "Y_test = np.array(df2['target']).reshape(-1, 1)\n",
    "X_test = np.array(df2.drop(columns={'target'}))\n",
    "\n",
    "pipeline = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                        max_depth=20,\n",
    "                                        min_samples_leaf=4, \n",
    "                                        min_samples_split=3,\n",
    "                                        n_estimators=500))\n",
    "]\n",
    "\n",
    "best = Pipeline(pipeline)\n",
    "\n",
    "Y_train = Y_train.ravel()\n",
    "Y_test = Y_test.ravel()\n",
    "\n",
    "best.fit(X_train, Y_train)\n",
    "\n",
    "print(best.score(X_test, Y_test))\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Please leave the stuff below as-is in your file. \n",
    "\n",
    "This will take your best model and score it with the test data. If you want to test to make sure that yours works, make a copy of the data file and rename it testing.csv, then make sure this runs ok. I will do the same, but the contents of my test file will be different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Test Data\n",
    "test_df = pd.read_csv(\"testing.csv\")\n",
    "test_df = test_df.drop(columns={\"id\"})\n",
    "#Create tests and score\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"target\"}))\n",
    "\n",
    "preds = best.predict(test_X)\n",
    "\n",
    "roc_score = roc_auc_score(test_y, preds)\n",
    "acc_score = accuracy_score(test_y, preds)\n",
    "\n",
    "print(roc_score)\n",
    "print(acc_score)\n",
    "print(name, np.mean([roc_score, acc_score]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Accuracy Changes Were Used\n",
    "\n",
    "Please list here what you did to try to increase accuracy and/or limit overfitting:\n",
    "<ul>\n",
    "<li> I put in some hyperparameters to reduce the overfitting done and tried to find the best hyperparameters by using a gridsearch to slove for the optimal slection of parameters given. \n",
    "<li> In addition, to improve accuracy I used cross validation to better evaluate our limited training data\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
